# Дерева прийняття рішень для таргетування реклами в соціальних мережах

## Вступ

У цьому блокноті ми аналізуємо датасет `Social_Network_Ads.csv` з метою розробки моделі для таргетування реклами в соціальних мережах. Ми використовуємо алгоритм дерев прийняття рішень (Decision Tree Classification), який дозволяє визначити, яким користувачам варто показувати рекламу на основі їхнього віку та приблизної зарплати.

## Зміст
1. [Завантаження та огляд даних](#1-завантаження-та-огляд-даних)
2. [Аналіз даних](#2-аналіз-даних)
3. [Підготовка даних](#3-підготовка-даних)
4. [Побудова та навчання моделі](#4-побудова-та-навчання-моделі)
5. [Оцінка моделі](#5-оцінка-моделі)
6. [Оптимізація моделі](#6-оптимізація-моделі)
7. [Інтерпретація результатів](#7-інтерпретація-результатів)
8. [Висновки](#8-висновки)

## 1. Завантаження та огляд даних

Спочатку ми імпортуємо необхідні бібліотеки та завантажуємо датасет:

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn import tree
import warnings
warnings.filterwarnings('ignore')

# Завантаження даних
data = pd.read_csv('Social_Network_Ads.csv')

# Виведення перших рядків даних для ознайомлення
print("Перші 5 рядків даних:")
print(data.head())
```

**Результат:**
```
Перші 5 рядків даних:
   Age  EstimatedSalary  Purchased
0   19            19000          0
1   35            20000          0
2   26            43000          0
3   27            57000          0
4   19            76000          0
```

Тепер подивимось загальну інформацію про датасет:

```python
print("\nІнформація про датасет:")
print(data.info())

print("\nСтатистика датасету:")
print(data.describe())
```

**Результат:**
```
Інформація про датасет:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 400 entries, 0 to 399
Data columns (total 3 columns):
 #   Column           Non-Null Count  Dtype
---  ------           --------------  -----
 0   Age              400 non-null    int64
 1   EstimatedSalary  400 non-null    int64
 2   Purchased        400 non-null    int64
dtypes: int64(3)
memory usage: 9.5 KB
None

Статистика датасету:
              Age  EstimatedSalary   Purchased
count  400.000000       400.000000  400.000000
mean    37.655000     69742.500000    0.357500
std     10.482877     34096.960282    0.479864
min     18.000000     15000.000000    0.000000
25%     29.750000     43000.000000    0.000000
50%     37.000000     70000.000000    0.000000
75%     46.000000     88000.000000    1.000000
max     60.000000    150000.000000    1.000000
```

### Пояснення використаних функцій:
- **data.info()** - надає загальну інформацію про датасет: кількість записів, типи даних та наявність пропущених значень.
- **data.describe()** - генерує статистичні показники для числових колонок: середнє значення, стандартне відхилення, мінімум, максимум та квартилі.

## 2. Аналіз даних

Перевіримо наявність пропущених значень:

```python
print("\nКількість пропущених значень:")
print(data.isnull().sum())
```

**Результат:**
```
Кількість пропущених значень:
Age                0
EstimatedSalary    0
Purchased          0
dtype: int64
```

Аналіз цільової змінної:

```python
print("\nРозподіл цільової змінної 'Purchased':")
print(data['Purchased'].value_counts())
```

**Результат:**
```
Розподіл цільової змінної 'Purchased':
Purchased
0    257
1    143
Name: count, dtype: int64
```

### Пояснення змінних у датасеті:
- **Age** - вік користувача соціальної мережі (в роках)
- **EstimatedSalary** - орієнтовна зарплата користувача (в умовних одиницях)
- **Purchased** - цільова змінна, яка показує, чи придбав користувач товар після перегляду реклами (1 - так, 0 - ні)

### Аналіз розподілу даних:

Дані в нашому датасеті включають 400 записів, і вони не мають пропущених значень. У датасеті наявний дисбаланс класів: 257 користувачів (64.25%) не придбали товар, а 143 користувачі (35.75%) здійснили покупку після перегляду реклами.

## 3. Підготовка даних

Для побудови моделі нам потрібно розділити дані на ознаки (features) та цільову змінну (target):

```python
# Підготовка даних
X = data[['Age', 'EstimatedSalary']]
y = data['Purchased']

# Розділення даних на тренувальну та тестову вибірки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
```

### Пояснення використаних функцій:
- **train_test_split()** - функція з бібліотеки scikit-learn, яка розділяє дані на тренувальну та тестову вибірки.
  - **test_size=0.25** - 25% даних використовуються для тестування моделі
  - **random_state=42** - забезпечує відтворюваність результатів (при кожному запуску дані будуть розділені однаково)

## 4. Побудова та навчання моделі

```python
# Навчання моделі дерева рішень
dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_classifier.fit(X_train, y_train)
```

### Пояснення використаних функцій і термінів:
- **DecisionTreeClassifier** - клас з бібліотеки scikit-learn для створення моделі дерева рішень для класифікації.
- **criterion='entropy'** - критерій для вибору атрибуту для розбиття вузла дерева:
  - **Ентропія (Entropy)** - міра невизначеності або "безладу" в даних. Формула: $H(S) = -\sum_{i=1}^{c} p_i \log_2(p_i)$, де $p_i$ - частка елементів класу $i$ в наборі $S$.
  - Альтернативним критерієм є **Gini impurity** (індекс Джині), який вимірює ймовірність неправильної класифікації.
- **fit()** - метод для навчання моделі на тренувальних даних.

## 5. Оцінка моделі

```python
# Прогнозування
y_pred = dt_classifier.predict(X_test)

# Оцінка моделі
print("\nТочність моделі на тестових даних:")
print(accuracy_score(y_test, y_pred))

print("\nМатриця помилок:")
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)

print("\nЗвіт класифікації:")
print(classification_report(y_test, y_pred))
```

**Результат:**
```
Точність моделі на тестових даних:
0.84

Матриця помилок:
[[55  8]
 [ 8 29]]

Звіт класифікації:
              precision    recall  f1-score   support
           0       0.87      0.87      0.87        63
           1       0.78      0.78      0.78        37
    accuracy                           0.84       100
   macro avg       0.83      0.83      0.83       100
weighted avg       0.84      0.84      0.84       100
```

### Пояснення метрик оцінки моделі:
- **Точність (Accuracy)** - частка правильно класифікованих прикладів. У нашому випадку точність складає 84%.
- **Матриця помилок (Confusion Matrix)** - таблиця, що показує кількість правильних і неправильних передбачень моделі в порівнянні з фактичними даними:
  - Істинно-негативні (True Negatives, TN) = 55 (користувачі, які не купили і модель правильно це передбачила)
  - Помилково-позитивні (False Positives, FP) = 8 (користувачі, які не купили, але модель помилково передбачила покупку)
  - Помилково-негативні (False Negatives, FN) = 8 (користувачі, які купили, але модель помилково передбачила відсутність покупки)
  - Істинно-позитивні (True Positives, TP) = 29 (користувачі, які купили і модель правильно це передбачила)
- **Precision (Точність)** - частка правильно передбачених позитивних результатів серед усіх передбачених позитивних результатів. Формула: $Precision = TP / (TP + FP)$
- **Recall (Повнота)** - частка правильно передбачених позитивних результатів серед усіх фактичних позитивних результатів. Формула: $Recall = TP / (TP + FN)$
- **F1-score** - гармонічне середнє між точністю та повнотою. Формула: $F1 = 2 \times (Precision \times Recall) / (Precision + Recall)$

## 6. Оптимізація моделі

### Аналіз важливості ознак

```python
print("\nВажливість ознак:")
feature_importance = pd.DataFrame({'feature': X.columns, 'importance': dt_classifier.feature_importances_})
print(feature_importance.sort_values('importance', ascending=False))
```

**Результат:**
```
Важливість ознак:
           feature  importance
1  EstimatedSalary    0.572587
0              Age    0.427413
```

### Пошук оптимальної глибини дерева

```python
max_depths = range(1, 20)
accuracies = []

for depth in max_depths:
    dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)
    dt_classifier.fit(X_train, y_train)
    y_pred = dt_classifier.predict(X_test)
    accuracies.append(accuracy_score(y_test, y_pred))

best_depth = max_depths[np.argmax(accuracies)]
print(f"\nОптимальна глибина дерева: {best_depth}")
```

**Результат:**
```
Оптимальна глибина дерева: 2
```

### Покращення моделі з оптимальною глибиною

```python
dt_classifier_best = DecisionTreeClassifier(criterion='entropy', max_depth=best_depth, random_state=42)
dt_classifier_best.fit(X_train, y_train)
y_pred_best = dt_classifier_best.predict(X_test)

print("\nТочність покращеної моделі на тестових даних:")
print(accuracy_score(y_test, y_pred_best))

print("\nЗвіт класифікації для покращеної моделі:")
print(classification_report(y_test, y_pred_best))
```

**Результат:**
```
Точність покращеної моделі на тестових даних:
0.92

Звіт класифікації для покращеної моделі:
              precision    recall  f1-score   support
           0       0.97      0.90      0.93        63
           1       0.85      0.95      0.90        37
    accuracy                           0.92       100
   macro avg       0.91      0.93      0.92       100
weighted avg       0.92      0.92      0.92       100
```

### Порівняння критеріїв розділення

```python
criterions = ['gini', 'entropy']
criterion_accuracies = []

for criterion in criterions:
    dt_classifier = DecisionTreeClassifier(criterion=criterion, max_depth=best_depth, random_state=42)
    dt_classifier.fit(X_train, y_train)
    y_pred = dt_classifier.predict(X_test)
    criterion_accuracies.append(accuracy_score(y_test, y_pred))

print("\nПорівняння критеріїв розділення:")
for criterion, accuracy in zip(criterions, criterion_accuracies):
    print(f"{criterion}: {accuracy:.4f}")
```

**Результат:**
```
Порівняння критеріїв розділення:
gini: 0.9200
entropy: 0.9200
```

### Пояснення параметрів оптимізації:
- **max_depth** - максимальна глибина дерева. Обмеження глибини запобігає перенавчанню (overfitting).
- **Перенавчання (Overfitting)** - явище, коли модель занадто добре "запам'ятовує" тренувальні дані, але погано узагальнює нові дані.
- **Гіперпараметри (Hyperparameters)** - параметри, які визначають структуру моделі та процес її навчання (наприклад, глибина дерева, критерій розбиття).

## 7. Інтерпретація результатів

На основі отриманих результатів можемо зробити такі висновки:

1. **Початкова модель** мала точність 84%, що є досить хорошим результатом, але залишає простір для покращення.

2. **Важливість ознак**:
   - **EstimatedSalary (Орієнтовна зарплата)** має важливість 57.26%, що робить її найважливішою ознакою для прийняття рішення.
   - **Age (Вік)** має важливість 42.74%.

3. **Оптимізована модель** з глибиною дерева 2 досягла точності 92%, що є значним покращенням порівняно з початковою моделлю.

4. **Критерії розбиття**:
   - Як Gini, так і Entropy дають однакову точність (92%) для оптимізованої моделі, що свідчить про стабільність моделі незалежно від обраного критерію.

5. **Метрики класифікації оптимізованої моделі**:
   - **Precision для класу 0 (не купили)**: 0.97 - модель дуже точно передбачає користувачів, які не куплять товар.
   - **Precision для класу 1 (купили)**: 0.85 - точність передбачення користувачів, які здійснять покупку, також висока.
   - **Recall для класу 0**: 0.90 - модель знаходить 90% користувачів, які не куплять товар.
   - **Recall для класу 1**: 0.95 - модель знаходить 95% користувачів, які здійснять покупку, що є чудовим результатом для таргетування реклами.

## 8. Висновки

У цьому блокноті ми успішно розробили модель класифікації на основі дерева прийняття рішень для таргетування реклами в соціальних мережах. Основні висновки:

1. **Простота моделі**: Оптимальна глибина дерева складає всього 2 рівні, що робить модель простою для інтерпретації та застосування.

2. **Висока точність**: Модель досягає точності 92% на тестових даних, що є відмінним результатом для бізнес-застосування.

3. **Ефективне таргетування**: Модель особливо добре виявляє користувачів, які з високою ймовірністю здійснять покупку (recall 95%), що дозволяє ефективно націлювати рекламу на потенційних клієнтів.

4. **Важливість ознак**: Орієнтовна зарплата є найважливішим фактором для передбачення схильності до покупки, але вік також має значний вплив.

5. **Практичне застосування**: Ця модель може бути використана рекламодавцями для оптимізації своїх рекламних кампаній, показуючи рекламу тільки тим користувачам, які з високою ймовірністю здійснять покупку, що дозволить зменшити витрати на рекламу та підвищити ROI (Return on Investment).

### Рекомендації для покращення моделі:
1. **Включення додаткових ознак**: Додавання інших демографічних або поведінкових ознак користувачів може ще більше підвищити точність моделі.
2. **Регуляризація**: Застосування додаткових методів регуляризації може допомогти запобігти перенавчанню при включенні більшої кількості ознак.
3. **Ансамблеві методи**: Використання ансамблевих методів, таких як Random Forest або Gradient Boosting, може підвищити точність та стабільність моделі.

## Глосарій термінів

1. **Дерево прийняття рішень (Decision Tree)** - алгоритм машинного навчання, який використовує деревоподібну структуру для моделювання рішень та їх наслідків. Кожен внутрішній вузол представляє перевірку атрибуту, кожна гілка - результат цієї перевірки, а кожен листовий вузол - клас або значення.

2. **Ентропія (Entropy)** - міра невизначеності або "безладу" в даних, яка використовується як критерій розбиття в деревах рішень.

3. **Індекс Джині (Gini Impurity)** - міра, що відображає ймовірність неправильної класифікації випадково вибраного елемента, якщо він класифікований випадково згідно з розподілом класів у наборі.

4. **Перенавчання (Overfitting)** - явище, коли модель занадто добре підлаштовується під тренувальні дані, але погано працює на нових, раніше не бачених даних.

5. **Недонавчання (Underfitting)** - протилежне до перенавчання явище, коли модель занадто проста і не може вловити складні закономірності в даних.

6. **Точність (Accuracy)** - частка правильно класифікованих прикладів серед усіх прикладів.

7. **Precision (Точність у контексті класифікації)** - частка правильно передбачених позитивних результатів серед усіх передбачених позитивних результатів.

8. **Recall (Повнота)** - частка правильно передбачених позитивних результатів серед усіх фактичних позитивних результатів.

9. **F1-score** - гармонічне середнє між precision та recall, що дозволяє оцінити баланс між цими двома метриками.

10. **Матриця помилок (Confusion Matrix)** - таблиця, що показує кількість правильних і неправильних передбачень моделі в порівнянні з фактичними даними.

11. **Важливість ознак (Feature Importance)** - міра впливу кожної ознаки на прогноз моделі.

12. **Регуляризація (Regularization)** - методи, що запобігають перенавчанню моделі шляхом додавання додаткових обмежень або штрафів.

13. **Гіперпараметри (Hyperparameters)** - параметри моделі, які встановлюються перед початком процесу навчання і не змінюються під час нього.

14. **Таргетування реклами** - процес показу реклами конкретній аудиторії на основі демографічних, географічних або поведінкових характеристик.

15. **ROI (Return on Investment)** - показник ефективності інвестицій, який вимірює прибуток від вкладених коштів.

## Корисні посилання
- [Scikit-learn: Decision Trees](https://scikit-learn.org/stable/modules/tree.html)
- [Entropy in Decision Trees](https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain)
- [Gini Impurity](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity)
- [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)
- [Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)
- [Overfitting and Underfitting](https://en.wikipedia.org/wiki/Overfitting)
